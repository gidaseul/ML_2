{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "'''\n",
    "\n",
    "ML 기말 프로젝트 base model 자리에 있질 않네 아주주\n",
    "\n",
    "* 모델 구조 변경으로 인한 성능 향상은 평가에서 제외.\n",
    "  구조 변경 예시) Conv & Linear layer 추가\n",
    "\n",
    "'''\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv1_M = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv2_M = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv3_M = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv4_M = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.GAP = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv1_M(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv2_M(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv3_M(out)\n",
    "\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv4_M(out)\n",
    "\n",
    "        out = self.conv5(out)\n",
    "        out = self.GAP(out)\n",
    "        # 해당 위치 out : classifier 직전 layer의 feature --\n",
    "\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torchvision import datasets, transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # # train과 test 데이터 디렉토리 경로 설정\n",
    "# train_dir = '/home/gidaseul/Documents/GitHub/ML_2/datas/MNIST/train'\n",
    "# test_dir = '/home/gidaseul/Documents/GitHub/ML_2/datas/MNIST/test'\n",
    "\n",
    "# # 데이터 전처리: MNIST 이미지를 RGB 채널로 처리\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),  # 입력 크기를 모델에 맞게 조정 (BaseModel은 32x32 크기 가정)\n",
    "#     transforms.ToTensor(),        # 이미지를 텐서로 변환\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # RGB 정규화\n",
    "# ])\n",
    "\n",
    "# # 데이터셋 로드\n",
    "# train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "# test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# # DataLoader 생성\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# # 데이터셋 크기 확인\n",
    "# print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "# print(f\"Number of test samples: {len(test_dataset)}\")\n",
    "\n",
    "# # 데이터 클래스 확인\n",
    "# print(f\"Classes: {train_dataset.classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1000\n",
      "Number of test samples: 100\n",
      "Classes: ['american_football', 'baseball', 'basketball', 'billiard_ball', 'bowling_ball', 'football', 'golf_ball', 'shuttlecock', 'tennis_ball', 'volleyball']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PadToSquare(object):\n",
    "    \"\"\"이미지 크기를 최대 크기로 패딩하여 정사각형으로 만듭니다.\"\"\"\n",
    "    def __init__(self, padding_value=0):\n",
    "        self.padding_value = padding_value\n",
    "        self.to_tensor = transforms.ToTensor()  # PIL 이미지 -> Tensor\n",
    "        self.to_pil = transforms.ToPILImage()  # Tensor -> PIL 이미지\n",
    "\n",
    "    def __call__(self, image):\n",
    "        # PIL 이미지를 텐서로 변환\n",
    "        image_tensor = self.to_tensor(image)\n",
    "\n",
    "        # 현재 이미지 크기 가져오기\n",
    "        _, height, width = image_tensor.shape\n",
    "        max_size = max(height, width)\n",
    "\n",
    "        # 패딩 계산 (좌, 상, 우, 하)\n",
    "        padding = (0, 0, max_size - width, max_size - height)  # (left, top, right, bottom)\n",
    "\n",
    "        # 패딩 추가 (텐서에 패딩)\n",
    "        padded_tensor = F.pad(image_tensor, padding, value=self.padding_value)\n",
    "\n",
    "        # 텐서를 다시 PIL 이미지로 변환\n",
    "        padded_image = self.to_pil(padded_tensor)\n",
    "        return padded_image\n",
    "\n",
    "# 데이터 디렉토리 설정\n",
    "train_dir = '/home/gidaseul/Documents/GitHub/ML_2/datas/SportsBall/train'\n",
    "test_dir = '/home/gidaseul/Documents/GitHub/ML_2/datas/SportsBall/test'\n",
    "\n",
    "# 데이터 전처리: MNIST 이미지를 RGB 채널로 처리\n",
    "transform = transforms.Compose([\n",
    "    PadToSquare(),  # 이미지 크기를 가장 큰 크기로 맞추기 위해 패딩\n",
    "    transforms.Resize((228, 228)),\n",
    "    transforms.ToTensor(),        # 이미지를 텐서로 변환\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # RGB 정규화\n",
    "])\n",
    "\n",
    "# 데이터셋 로드\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# 데이터셋 크기 확인\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")\n",
    "\n",
    "# 데이터 클래스 확인\n",
    "print(f\"Classes: {train_dataset.classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 모델, 손실 함수, 옵티마이저 정의\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BaseModel().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# 조기 종료 파라미터 설정\n",
    "early_stopping_patience = 10  # 개선되지 않으면 5 에폭 후 종료\n",
    "best_test_loss = float('inf')  # 최적의 검증 손실\n",
    "patience_counter = 0  # 개선되지 않은 에폭 수 카운트\n",
    "\n",
    "# Feature map 추출을 위한 forward hook 등록\n",
    "features = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    features.append(output.cpu().detach().numpy())\n",
    "\n",
    "hook = model.GAP.register_forward_hook(hook_fn)\n",
    "\n",
    "# 수정된 Feature 추출 함수 (불필요한 글로벌 변수 제거)\n",
    "def extract_features(model, loader, device):\n",
    "    features, labels_list = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # GAP 레이어를 통해 Latent Feature 추출\n",
    "            latent = model.GAP(model.conv5(model.conv4(model.conv3(model.conv2(model.conv1(images))))))\n",
    "            latent = latent.view(latent.size(0), -1)\n",
    "            features.append(latent.cpu().numpy())\n",
    "            labels_list.extend(labels.cpu().numpy())\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    return features, np.array(labels_list)\n",
    "\n",
    "def plot_tsne(features, labels, num_classes=10):\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_results = tsne.fit_transform(features)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for class_idx in range(num_classes):\n",
    "        idx = labels == class_idx\n",
    "        plt.scatter(tsne_results[idx, 0], tsne_results[idx, 1], label=f'Class {class_idx}', alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.title(\"t-SNE Visualization of Features\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 224.12 MiB is free. Process 20650 has 20.82 GiB memory in use. Including non-PyTorch memory, this process has 2.16 GiB memory in use. Of the allocated memory 1.96 GiB is allocated by PyTorch, and 12.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[1], line 81\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m     79\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1_M(out)\n\u001b[0;32m---> 81\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n\u001b[1;32m     82\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2_M(out)\n\u001b[1;32m     84\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(out)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    551\u001b[0m )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 224.12 MiB is free. Process 20650 has 20.82 GiB memory in use. Including non-PyTorch memory, this process has 2.16 GiB memory in use. Of the allocated memory 1.96 GiB is allocated by PyTorch, and 12.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "for epoch in range(100):\n",
    "    # Training Loop\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Evaluation Loop\n",
    "    model.eval()\n",
    "    test_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_acc = 100 * correct / total\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/100]\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "    # 학습률 조정 (ReduceLROnPlateau 사용)\n",
    "    scheduler.step(test_loss)  # test_loss를 전달하여 학습률을 조정\n",
    "\n",
    "    # Early Stopping 체크\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        patience_counter = 0  # 개선이 있었으므로 카운터 초기화\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"Patience Counter: {patience_counter}/{early_stopping_patience}\")\n",
    "\n",
    "    # 만약 patience_counter가 early_stopping_patience 이상이면 조기 종료\n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "    # t-SNE Visualization (5 epoch마다 실행)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        test_features, test_labels = extract_features(model, test_loader, device)\n",
    "        plot_tsne(test_features, test_labels, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base 기반으로 latent space의 중요성을 확인하는 방법에 대한 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 새로운 분류기를 정의하고 이를 Latent Space 기반으로 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Space 기반 분류기 정의\n",
    "class LatentClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Feature 추출\n",
    "train_features, train_labels = extract_features(model, train_loader, device)\n",
    "test_features, test_labels = extract_features(model, test_loader, device)\n",
    "\n",
    "# TensorDataset으로 변환\n",
    "train_features = torch.tensor(train_features, dtype=torch.float32)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "test_features = torch.tensor(test_features, dtype=torch.float32)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "train_dataset_latent = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_dataset_latent = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader_latent = torch.utils.data.DataLoader(train_dataset_latent, batch_size=64, shuffle=True)\n",
    "test_loader_latent = torch.utils.data.DataLoader(test_dataset_latent, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추가 부분: Latent Feature 추출 및 DataLoader 구성\n",
    "- 기존 학습 완료된 모델에서 Latent Space의 Feature를 추출하고, 새로운 DataLoader를 구성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Feature 추출\n",
    "train_features, train_labels = extract_features(model, train_loader, device)\n",
    "test_features, test_labels = extract_features(model, test_loader, device)\n",
    "\n",
    "# TensorDataset으로 변환\n",
    "train_features = torch.tensor(train_features, dtype=torch.float32)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "test_features = torch.tensor(test_features, dtype=torch.float32)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "train_dataset_latent = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_dataset_latent = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader_latent = torch.utils.data.DataLoader(train_dataset_latent, batch_size=64, shuffle=True)\n",
    "test_loader_latent = torch.utils.data.DataLoader(test_dataset_latent, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추가 부분: Latent Classifier 학습\n",
    "- Latent Space에서 추출한 Feature를 기반으로 새로운 분류기를 학습 및 평가.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]\n",
      "Train Loss: 2.2172, Train Acc: 20.60%\n",
      "Test Loss: 2.1584, Test Acc: 17.00%\n",
      "Epoch [2/50]\n",
      "Train Loss: 2.0711, Train Acc: 29.20%\n",
      "Test Loss: 2.0976, Test Acc: 28.00%\n",
      "Epoch [3/50]\n",
      "Train Loss: 1.9807, Train Acc: 30.80%\n",
      "Test Loss: 2.0509, Test Acc: 31.00%\n",
      "Epoch [4/50]\n",
      "Train Loss: 1.9097, Train Acc: 35.00%\n",
      "Test Loss: 1.9880, Test Acc: 26.00%\n",
      "Epoch [5/50]\n",
      "Train Loss: 1.8473, Train Acc: 36.30%\n",
      "Test Loss: 1.9561, Test Acc: 29.00%\n",
      "Epoch [6/50]\n",
      "Train Loss: 1.8218, Train Acc: 38.60%\n",
      "Test Loss: 1.9734, Test Acc: 32.00%\n",
      "Epoch [7/50]\n",
      "Train Loss: 1.7946, Train Acc: 38.80%\n",
      "Test Loss: 1.9190, Test Acc: 38.00%\n",
      "Epoch [8/50]\n",
      "Train Loss: 1.7483, Train Acc: 39.00%\n",
      "Test Loss: 1.9286, Test Acc: 32.00%\n",
      "Epoch [9/50]\n",
      "Train Loss: 1.7387, Train Acc: 40.40%\n",
      "Test Loss: 1.9213, Test Acc: 36.00%\n",
      "Epoch [10/50]\n",
      "Train Loss: 1.7094, Train Acc: 41.60%\n",
      "Test Loss: 1.9034, Test Acc: 37.00%\n",
      "Epoch [11/50]\n",
      "Train Loss: 1.6966, Train Acc: 42.10%\n",
      "Test Loss: 1.8768, Test Acc: 39.00%\n",
      "Epoch [12/50]\n",
      "Train Loss: 1.6867, Train Acc: 42.80%\n",
      "Test Loss: 1.8725, Test Acc: 42.00%\n",
      "Epoch [13/50]\n",
      "Train Loss: 1.6638, Train Acc: 42.30%\n",
      "Test Loss: 1.8637, Test Acc: 37.00%\n",
      "Epoch [14/50]\n",
      "Train Loss: 1.6555, Train Acc: 42.20%\n",
      "Test Loss: 1.8590, Test Acc: 37.00%\n",
      "Epoch [15/50]\n",
      "Train Loss: 1.6429, Train Acc: 44.40%\n",
      "Test Loss: 1.8440, Test Acc: 37.00%\n",
      "Epoch [16/50]\n",
      "Train Loss: 1.6401, Train Acc: 43.90%\n",
      "Test Loss: 1.8564, Test Acc: 41.00%\n",
      "Epoch [17/50]\n",
      "Train Loss: 1.6498, Train Acc: 43.70%\n",
      "Test Loss: 1.8918, Test Acc: 37.00%\n",
      "Epoch [18/50]\n",
      "Train Loss: 1.6146, Train Acc: 43.40%\n",
      "Test Loss: 1.8420, Test Acc: 38.00%\n",
      "Epoch [19/50]\n",
      "Train Loss: 1.5979, Train Acc: 45.40%\n",
      "Test Loss: 1.8090, Test Acc: 38.00%\n",
      "Epoch [20/50]\n",
      "Train Loss: 1.5871, Train Acc: 44.90%\n",
      "Test Loss: 1.8002, Test Acc: 41.00%\n",
      "Epoch [21/50]\n",
      "Train Loss: 1.5812, Train Acc: 46.20%\n",
      "Test Loss: 1.8520, Test Acc: 36.00%\n",
      "Epoch [22/50]\n",
      "Train Loss: 1.5876, Train Acc: 46.00%\n",
      "Test Loss: 1.8318, Test Acc: 38.00%\n",
      "Epoch [23/50]\n",
      "Train Loss: 1.5823, Train Acc: 45.70%\n",
      "Test Loss: 1.7931, Test Acc: 42.00%\n",
      "Epoch [24/50]\n",
      "Train Loss: 1.5466, Train Acc: 46.00%\n",
      "Test Loss: 1.8025, Test Acc: 38.00%\n",
      "Epoch [25/50]\n",
      "Train Loss: 1.5488, Train Acc: 47.20%\n",
      "Test Loss: 1.7942, Test Acc: 39.00%\n",
      "Epoch [26/50]\n",
      "Train Loss: 1.5480, Train Acc: 47.00%\n",
      "Test Loss: 1.8053, Test Acc: 41.00%\n",
      "Epoch [27/50]\n",
      "Train Loss: 1.5533, Train Acc: 45.90%\n",
      "Test Loss: 1.8359, Test Acc: 38.00%\n",
      "Epoch [28/50]\n",
      "Train Loss: 1.5537, Train Acc: 46.80%\n",
      "Test Loss: 1.8875, Test Acc: 39.00%\n",
      "Epoch [29/50]\n",
      "Train Loss: 1.5339, Train Acc: 46.20%\n",
      "Test Loss: 1.8160, Test Acc: 41.00%\n",
      "Epoch [30/50]\n",
      "Train Loss: 1.5164, Train Acc: 46.50%\n",
      "Test Loss: 1.8056, Test Acc: 40.00%\n",
      "Epoch [31/50]\n",
      "Train Loss: 1.5146, Train Acc: 46.80%\n",
      "Test Loss: 1.8151, Test Acc: 40.00%\n",
      "Epoch [32/50]\n",
      "Train Loss: 1.5114, Train Acc: 47.50%\n",
      "Test Loss: 1.7718, Test Acc: 40.00%\n",
      "Epoch [33/50]\n",
      "Train Loss: 1.5237, Train Acc: 47.00%\n",
      "Test Loss: 1.8318, Test Acc: 40.00%\n",
      "Epoch [34/50]\n",
      "Train Loss: 1.5178, Train Acc: 48.00%\n",
      "Test Loss: 1.7652, Test Acc: 42.00%\n",
      "Epoch [35/50]\n",
      "Train Loss: 1.4954, Train Acc: 49.20%\n",
      "Test Loss: 1.7589, Test Acc: 40.00%\n",
      "Epoch [36/50]\n",
      "Train Loss: 1.5087, Train Acc: 46.30%\n",
      "Test Loss: 1.7800, Test Acc: 41.00%\n",
      "Epoch [37/50]\n",
      "Train Loss: 1.5106, Train Acc: 46.50%\n",
      "Test Loss: 1.7763, Test Acc: 44.00%\n",
      "Epoch [38/50]\n",
      "Train Loss: 1.4740, Train Acc: 48.20%\n",
      "Test Loss: 1.7616, Test Acc: 40.00%\n",
      "Epoch [39/50]\n",
      "Train Loss: 1.4589, Train Acc: 48.70%\n",
      "Test Loss: 1.7492, Test Acc: 42.00%\n",
      "Epoch [40/50]\n",
      "Train Loss: 1.4651, Train Acc: 49.40%\n",
      "Test Loss: 1.8044, Test Acc: 40.00%\n",
      "Epoch [41/50]\n",
      "Train Loss: 1.4449, Train Acc: 49.40%\n",
      "Test Loss: 1.7770, Test Acc: 41.00%\n",
      "Epoch [42/50]\n",
      "Train Loss: 1.4477, Train Acc: 48.00%\n",
      "Test Loss: 1.8029, Test Acc: 40.00%\n",
      "Epoch [43/50]\n",
      "Train Loss: 1.4443, Train Acc: 48.40%\n",
      "Test Loss: 1.7201, Test Acc: 40.00%\n",
      "Epoch [44/50]\n",
      "Train Loss: 1.4477, Train Acc: 48.80%\n",
      "Test Loss: 1.7558, Test Acc: 40.00%\n",
      "Epoch [45/50]\n",
      "Train Loss: 1.4422, Train Acc: 48.30%\n",
      "Test Loss: 1.7115, Test Acc: 38.00%\n",
      "Epoch [46/50]\n",
      "Train Loss: 1.4400, Train Acc: 49.20%\n",
      "Test Loss: 1.7780, Test Acc: 40.00%\n",
      "Epoch [47/50]\n",
      "Train Loss: 1.4222, Train Acc: 48.40%\n",
      "Test Loss: 1.7328, Test Acc: 42.00%\n",
      "Epoch [48/50]\n",
      "Train Loss: 1.4250, Train Acc: 49.30%\n",
      "Test Loss: 1.7607, Test Acc: 41.00%\n",
      "Epoch [49/50]\n",
      "Train Loss: 1.4245, Train Acc: 49.20%\n",
      "Test Loss: 1.7319, Test Acc: 41.00%\n",
      "Epoch [50/50]\n",
      "Train Loss: 1.4156, Train Acc: 49.20%\n",
      "Test Loss: 1.7420, Test Acc: 39.00%\n"
     ]
    }
   ],
   "source": [
    "# Latent Classifier 학습\n",
    "latent_classifier = LatentClassifier(input_dim=train_features.shape[1], num_classes=10).to(device)\n",
    "criterion_latent = nn.CrossEntropyLoss()\n",
    "optimizer_latent = optim.Adam(latent_classifier.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 Loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    # Training Loop\n",
    "    latent_classifier.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for features, labels in train_loader_latent:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "        optimizer_latent.zero_grad()\n",
    "        outputs = latent_classifier(features)\n",
    "        loss = criterion_latent(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_latent.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    train_loss = running_loss / len(train_loader_latent)\n",
    "\n",
    "    # Evaluation Loop\n",
    "    latent_classifier.eval()\n",
    "    test_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader_latent:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = latent_classifier(features)\n",
    "            loss = criterion_latent(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_acc = 100 * correct / total\n",
    "    test_loss = test_loss / len(test_loader_latent)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
